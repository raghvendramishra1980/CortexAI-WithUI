# OpenAI Project - Claude Context

## Project Overview
Multi-provider AI chat CLI with token tracking and cost calculation.

## Quick Reference

### Providers
- **OpenAI**: `api/openai_client.py` - GPT models
- **Gemini**: `api/google_gemini_client.py` - Google models
- **DeepSeek**: `api/deepseek_client.py` - DeepSeek models
- **Grok**: `api/grok_client.py` - X.AI models

### Key Files
- `main.py` - Entry point, chat loop, model initialization
- `utils/token_tracker.py` - Tracks tokens (prompt/completion/total)
- `utils/cost_calculator.py` - Calculates costs (separate from token tracking)
- `config/pricing.py` - Pricing data for all models
- `.env` - Configuration (API keys, MODEL_TYPE selection)

### Architecture
- All clients inherit from `api/base_client.py::BaseAIClient`
- TokenTracker and CostCalculator are independent modules
- Pricing stored centrally in `config/pricing.py`

### Common Tasks
- **Add new provider**: Create client in `api/`, add pricing, update `main.py`
- **Update pricing**: Edit `config/pricing.py`
- **Switch model**: Change `MODEL_TYPE` in `.env`

### Current Config
- Active model: DeepSeek (`deepseek-chat`)
- Features: Token tracking, cost calculation, session stats
- Commands: `stats`, `help`, `exit`

## File Purpose Quick Map
```
api/base_client.py       → Abstract base for all clients
api/*_client.py          → Provider-specific implementations
config/pricing.py        → Model pricing data (per million tokens)
utils/token_tracker.py   → Token counting only
utils/cost_calculator.py → Cost calculation only (uses pricing.py)
main.py                  → CLI, initialization, stats display
```

## Recent Changes
- Added Grok (X.AI) support
- Implemented cost tracking system
- Separated token tracking from cost calculation
- Updated README with full documentation

## Design Principles
- Separation of concerns (tokens ≠ costs)
- Provider-agnostic base client
- Environment-based configuration
- Real-time cost display per request