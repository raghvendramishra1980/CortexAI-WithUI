# OpenAI Project - Claude Context

## Project Overview
Multi-provider AI chat CLI with token tracking and cost calculation.

## Quick Reference

### Providers
- **OpenAI**: `api/openai_client.py` - GPT models
- **Gemini**: `api/google_gemini_client.py` - Google models
- **DeepSeek**: `api/deepseek_client.py` - DeepSeek models
- **Grok**: `api/grok_client.py` - X.AI models

### Key Files
- `main.py` - **Thin CLI layer** (user I/O only)
- `orchestrator/core.py` - **NEW**: Core business logic (CortexOrchestrator)
- `models/user_context.py` - **NEW**: Session metadata container
- `utils/token_tracker.py` - Tracks tokens (prompt/completion/total)
- `utils/cost_calculator.py` - Calculates costs (separate from token tracking)
- `utils/logger.py` - Structured JSON logging system
- `config/pricing.py` - Pricing data for all models
- `.env` - Configuration (API keys, MODEL_TYPE, LOG_LEVEL, LOG_TO_CONSOLE)

### Architecture
**NEW: Orchestrator Pattern (Refactored 2026-01-07)**
```
CLI Layer (main.py)                  → Handles user I/O only
    ↓
CortexOrchestrator (orchestrator/core.py)  → Business logic
    ↓
BaseAIClient implementations (api/)  → Provider-specific calls
    ↓
UnifiedResponse / MultiUnifiedResponse     → Standardized responses
```

**Key Components**:
- `orchestrator/core.py` - **CortexOrchestrator** (stateless business logic)
  - `ask(prompt, model_type, context)` - Single model requests
  - `compare(prompt, models_list, context)` - Multi-model comparisons
- `models/user_context.py` - **UserContext** (session metadata container)
- All clients inherit from `api/base_client.py::BaseAIClient`
- **UnifiedResponse Contract**: All `get_completion()` methods return `UnifiedResponse` (never raise exceptions)
  - Defined in `models/unified_response.py`
  - Immutable frozen dataclass with: `request_id`, `text`, `provider`, `model`, `latency_ms`, `token_usage`, `estimated_cost`, `finish_reason`, `error`
  - Errors returned as `NormalizedError` inside response (codes: timeout, auth, rate_limit, bad_request, provider_error, unknown)
- TokenTracker and CostCalculator are independent modules
- Pricing stored centrally in `config/pricing.py`

### Common Tasks
- **Add new provider**: Create client in `api/`, add pricing, update `main.py`
- **Update pricing**: Edit `config/pricing.py`
- **Switch model**: Change `MODEL_TYPE` in `.env`

### Current Config
- Active model: Grok (`grok-4-latest`)
- Features: Token tracking, cost calculation, session stats, **structured JSON logging**
- Commands: `stats`, `help`, `exit`
- Logging: Files in `logs/` directory (app.log, error.log, debug.log)

## File Purpose Quick Map
```
main.py                  → Thin CLI layer (user I/O only)
orchestrator/core.py     → Business logic orchestrator (stateless)
orchestrator/multi_orchestrator.py → Multi-model comparison logic
models/user_context.py   → Session metadata container
models/unified_response.py → Single response model
models/multi_unified_response.py → Multi-model response model
api/base_client.py       → Abstract base for all clients
api/*_client.py          → Provider-specific implementations
config/pricing.py        → Model pricing data (per million tokens)
utils/token_tracker.py   → Token counting only
utils/cost_calculator.py → Cost calculation only (uses pricing.py)
utils/logger.py          → Structured JSON logging (enterprise-ready)
logs/                    → Log files (app.log, error.log, debug.log)
LOGGING.md               → Complete logging documentation
REFACTORING_SUMMARY.md   → Refactoring documentation
```

## Recent Changes
- **✨ MAJOR REFACTOR (2026-01-07): Separated business logic from CLI**
  - Created `orchestrator/core.py` with `CortexOrchestrator` class
  - Created `models/user_context.py` for session metadata
  - Refactored `main.py` to be a thin CLI layer
  - Enables future FastAPI, SDK, and other integrations
  - See `REFACTORING_SUMMARY.md` for full details
- Added enterprise-ready structured JSON logging system
  - All logs go to `logs/` directory (console stays clean)
  - JSON format for ELK/Loki/Datadog integration
  - Rotating file handlers (10MB max, 5 backups)
  - Environment-based config (LOG_LEVEL, LOG_TO_CONSOLE)
- Added Grok (X.AI) support
- Implemented cost tracking system
- Separated token tracking from cost calculation

## Design Principles
- **Orchestrator Pattern**: Business logic separated from UI
- **Stateless Design**: All context passed via UserContext
- Separation of concerns (tokens ≠ costs ≠ logging ≠ orchestration ≠ UI)
- Provider-agnostic base client
- Environment-based configuration
- Real-time cost display per request
- Clean console for chat, logs to files
- Enterprise-ready logging (JSON, rotating, structured)
- Future-ready (FastAPI, SDK, gRPC ready)

## Logging System (NEW)
- **Location**: `logs/` directory
- **Format**: Structured JSON for log aggregation
- **Files**: app.log (INFO+), error.log (ERROR+), debug.log (DEBUG, if enabled)
- **Config**: LOG_LEVEL (DEBUG/INFO/WARNING/ERROR/CRITICAL), LOG_TO_CONSOLE (true/false)
- **Rotation**: 10MB max per file, 5 backups
- **Integration**: Ready for ELK Stack, Grafana Loki, Datadog
- **Privacy**: No user messages or API keys logged