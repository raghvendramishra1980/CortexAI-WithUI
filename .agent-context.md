# OpenAI Project - Claude Context

## Project Overview
Multi-provider AI chat CLI with token tracking and cost calculation.

## Quick Reference

### Providers
- **OpenAI**: `api/openai_client.py` - GPT models
- **Gemini**: `api/google_gemini_client.py` - Google models
- **DeepSeek**: `api/deepseek_client.py` - DeepSeek models
- **Grok**: `api/grok_client.py` - X.AI models

### Key Files
- `main.py` - Entry point, chat loop, model initialization
- `utils/token_tracker.py` - Tracks tokens (prompt/completion/total)
- `utils/cost_calculator.py` - Calculates costs (separate from token tracking)
- `utils/logger.py` - **NEW**: Structured JSON logging system
- `config/pricing.py` - Pricing data for all models
- `.env` - Configuration (API keys, MODEL_TYPE, LOG_LEVEL, LOG_TO_CONSOLE)

### Architecture
- All clients inherit from `api/base_client.py::BaseAIClient`
- **UnifiedResponse Contract**: All `get_completion()` methods return `UnifiedResponse` (never raise exceptions)
  - Defined in `models/unified_response.py`
  - Immutable frozen dataclass with: `request_id`, `text`, `provider`, `model`, `latency_ms`, `token_usage`, `estimated_cost`, `finish_reason`, `error`
  - Errors returned as `NormalizedError` inside response (codes: timeout, auth, rate_limit, bad_request, provider_error, unknown)
- TokenTracker and CostCalculator are independent modules
- Pricing stored centrally in `config/pricing.py`

### Common Tasks
- **Add new provider**: Create client in `api/`, add pricing, update `main.py`
- **Update pricing**: Edit `config/pricing.py`
- **Switch model**: Change `MODEL_TYPE` in `.env`

### Current Config
- Active model: Grok (`grok-4-latest`)
- Features: Token tracking, cost calculation, session stats, **structured JSON logging**
- Commands: `stats`, `help`, `exit`
- Logging: Files in `logs/` directory (app.log, error.log, debug.log)

## File Purpose Quick Map
```
api/base_client.py       → Abstract base for all clients
api/*_client.py          → Provider-specific implementations
config/pricing.py        → Model pricing data (per million tokens)
utils/token_tracker.py   → Token counting only
utils/cost_calculator.py → Cost calculation only (uses pricing.py)
utils/logger.py          → Structured JSON logging (enterprise-ready)
main.py                  → CLI, initialization, stats display
logs/                    → Log files (app.log, error.log, debug.log)
LOGGING.md               → Complete logging documentation
```

## Recent Changes
- **Added enterprise-ready structured JSON logging system**
  - All logs go to `logs/` directory (console stays clean)
  - JSON format for ELK/Loki/Datadog integration
  - Rotating file handlers (10MB max, 5 backups)
  - Environment-based config (LOG_LEVEL, LOG_TO_CONSOLE)
- Added Grok (X.AI) support
- Implemented cost tracking system
- Separated token tracking from cost calculation
- Updated README with full documentation

## Design Principles
- Separation of concerns (tokens ≠ costs ≠ logging)
- Provider-agnostic base client
- Environment-based configuration
- Real-time cost display per request
- Clean console for chat, logs to files
- Enterprise-ready logging (JSON, rotating, structured)

## Logging System (NEW)
- **Location**: `logs/` directory
- **Format**: Structured JSON for log aggregation
- **Files**: app.log (INFO+), error.log (ERROR+), debug.log (DEBUG, if enabled)
- **Config**: LOG_LEVEL (DEBUG/INFO/WARNING/ERROR/CRITICAL), LOG_TO_CONSOLE (true/false)
- **Rotation**: 10MB max per file, 5 backups
- **Integration**: Ready for ELK Stack, Grafana Loki, Datadog
- **Privacy**: No user messages or API keys logged