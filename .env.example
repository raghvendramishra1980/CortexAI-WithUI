# API Configuration
# Choose which model to use: 'openai', 'gemini', 'deepseek', or 'grok'
MODEL_TYPE=openai

# OpenAI API Configuration (required if MODEL_TYPE=openai)
OPENAI_API_KEY=your_openai_api_key_here

# Google Gemini API Configuration (required if MODEL_TYPE=gemini)
GOOGLE_GEMINI_API_KEY=your_google_gemini_api_key_here

# DeepSeek API Configuration (required if MODEL_TYPE=deepseek)
DEEPSEEK_API_KEY=your_deepseek_api_key_here

# Model Configuration
# For OpenAI models (e.g., gpt-3.5-turbo, gpt-4)
DEFAULT_OPENAI_MODEL=gpt-3.5-turbo

# For Gemini models (e.g., gemini-1.5-flash, gemini-2.5-flash-lite)
DEFAULT_GEMINI_MODEL=gemini-1.5-flash

# For DeepSeek models (e.g., deepseek-chat, deepseek-reasoner)
# deepseek-chat: Best for general conversation and non-technical discussion
# deepseek-reasoner: Best for advanced reasoning, math, and coding tasks
DEFAULT_DEEPSEEK_MODEL=deepseek-chat

# Grok API Configuration (required if MODEL_TYPE=grok)
GROK_API_KEY=your_grok_api_key_here

# For Grok models (e.g., grok-4-latest)
# grok-4-latest: Latest Grok model with advanced reasoning capabilities
DEFAULT_GROK_MODEL=grok-4-latest

# Conversation Context Configuration
# MAX_CONTEXT_MESSAGES: Maximum number of messages to keep in conversation history
# - Controls how many previous messages are sent to the model for context
# - Higher values provide more context but use more tokens (cost)
# - System prompts are not counted toward this limit
# - Default: 20 (10 user + 10 assistant messages)
# - Recommended range: 10-50 depending on use case and budget
MAX_CONTEXT_MESSAGES=20

# Compare Mode Configuration
# COMPARE_MODE: Enable multi-model comparison mode
# - true: Every prompt is sent to all configured models (from COMPARE_TARGETS in config.py)
# - false: Use single model specified by MODEL_TYPE (default behavior)
# - When enabled, all responses are shown side-by-side with cost/token comparison
# - Requires at least one API key configured
COMPARE_MODE=false

# Research / Web Search Configuration
# Tavily API for AI-powered web research
# - Reads JavaScript-rendered content (works on all modern sites)
# - Production-grade content extraction
# - Better relevance ranking
# - Cost: $1 per 1000 searches, free tier: 1000/month
# - Get your API key at: https://tavily.com
TAVILY_API_KEY=your_tavily_api_key_here

# RESEARCH_MODE: Default research mode for CLI (off or on)
# - off: No web research (fastest, cheapest)
# - on: Always use web research (recommended)
# - Note: CLI will prompt for preference at startup, this is just the default
RESEARCH_MODE=on

# RESEARCH_CACHE_TTL_SECONDS: Cache TTL for research results (in seconds)
# - Controls how long research results are cached
# - Default: 3600 (1 hour)
# - Higher values reduce API costs but may return stale data
RESEARCH_CACHE_TTL_SECONDS=3600

# Logging Configuration
# LOG_LEVEL: Set the logging level (DEBUG, INFO, WARNING, ERROR, CRITICAL)
# - DEBUG: Detailed information for diagnosing problems (verbose)
# - INFO: General informational messages (default, recommended for production)
# - WARNING: Warning messages for potentially problematic situations
# - ERROR: Error messages for serious problems
# - CRITICAL: Critical messages for very serious errors
LOG_LEVEL=INFO

# LOG_TO_CONSOLE: Whether to also output ERROR logs to console (stderr)
# - true: Error logs will be visible in console (in addition to files)
# - false: All logs only go to files, keeping console clean (recommended)
LOG_TO_CONSOLE=false

# Prompt Optimization Configuration
# ENABLE_PROMPT_OPTIMIZATION: Enable automatic prompt optimization before sending to AI
# - true: All prompts are automatically optimized using the configured provider
# - false: Prompts are sent as-is without optimization (default)
# - Note: Each optimization requires an additional API call, increasing costs
ENABLE_PROMPT_OPTIMIZATION=false

# PROMPT_OPTIMIZER_PROVIDER: AI provider to use for prompt optimization
# - openai: Use OpenAI (GPT models)
# - gemini: Use Google Gemini (recommended - has free tier!)
# - auto: Automatically select based on available API keys
PROMPT_OPTIMIZER_PROVIDER=gemini

# PROMPT_OPTIMIZER_MODEL: OpenAI model to use (if provider=openai)
# - gpt-4o-mini: Balanced performance and cost (recommended)
# - gpt-4o: Higher quality optimizations, higher cost
# - gpt-3.5-turbo: Faster and cheaper, lower quality
PROMPT_OPTIMIZER_MODEL=gpt-4o-mini

# PROMPT_OPTIMIZER_GEMINI_MODEL: Gemini model to use (if provider=gemini)
# - gemini-2.0-flash-exp: Latest experimental model (recommended, free tier)
# - gemini-1.5-flash: Stable, fast, free tier available
# - gemini-1.5-pro: Higher quality, more expensive
PROMPT_OPTIMIZER_GEMINI_MODEL=gemini-2.0-flash-exp

# PROMPT_OPTIMIZER_MAX_RETRIES: Maximum retry attempts for failed optimizations
# - Retries occur on API failures or validation errors
# - Exponential backoff is applied between retries
# - Default: 3
PROMPT_OPTIMIZER_MAX_RETRIES=3

# ============================================================================
# DATABASE CONFIGURATION
# ============================================================================

# PostgreSQL Database URL
# Format: postgresql+psycopg://username:password@host:port/database
#
# Local PostgreSQL (for development):
DATABASE_URL=postgresql+psycopg://cortex:your_password@localhost:5432/cortexai
#
# AWS RDS/Aurora PostgreSQL (for production):
# DATABASE_URL=postgresql+psycopg://cortex:your_password@your-rds-endpoint.region.rds.amazonaws.com:5432/cortexai?sslmode=require

# Database Connection Pool Settings
# DB_POOL_SIZE: Number of connections to keep open (default: 5)
# DB_MAX_OVERFLOW: Additional connections allowed when pool is full (default: 10)
# DB_POOL_TIMEOUT: Seconds to wait for a connection (default: 30)
DB_POOL_SIZE=5
DB_MAX_OVERFLOW=10
DB_POOL_TIMEOUT=30

# Database Schema
# DB_SCHEMA: PostgreSQL schema name (default: public)
DB_SCHEMA=public

# Usage Limits (optional - for enforcement)
# Set these to enable daily usage caps
# DAILY_TOKEN_CAP: Maximum tokens per day per user
# DAILY_COST_CAP: Maximum cost per day per user (in USD)
# Leave commented out to disable limits
# DAILY_TOKEN_CAP=100000
# DAILY_COST_CAP=5.00
